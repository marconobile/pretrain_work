{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from geqtrain.nn.nonlinearities import ShiftedSoftPlus, ShiftedSoftPlusModule, SwiGLUModule, SwiGLU\n",
    "from geqtrain.nn._fc import select_nonlinearity\n",
    "from e3nn.math import normalize2mom\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_gain(non_linearity:str, gain:float=None, use_normalize2mom:bool=False, seed: int=42):\n",
    "    activation = select_nonlinearity(non_linearity)\n",
    "    in_size = 512\n",
    "    out_size = in_size if non_linearity != \"swiglu\" else 2*in_size\n",
    "\n",
    "    if not gain and not use_normalize2mom: raise ValueError('no gain (nor automatic gain) provided, idk what to do')\n",
    "    if gain and use_normalize2mom: raise ValueError('both gain and automatic gain provided, idk what to do')\n",
    "\n",
    "  # todo implement automatic gain\n",
    "  # nonlinearity = {\n",
    "  #   None: None,\n",
    "  #   \"silu\": torch.nn.functional.silu,\n",
    "  #   \"ssp\": ShiftedSoftPlusModule,\n",
    "  #   \"selu\": torch.nn.functional.selu,\n",
    "  #   \"relu\": torch.nn.functional.relu,\n",
    "  #   \"swiglu\": SwiGLUModule,\n",
    "  # }[non_linearity]\n",
    "  # if use_normalize2mom: gain = normalize2mom()\n",
    "\n",
    "    incr_counter = 0\n",
    "    decr_counter = 0\n",
    "    for _ in tqdm(range(5000), desc=\"Test gain Progress\"):\n",
    "        seed = random.randint(0, 100000)\n",
    "        torch.manual_seed(seed)\n",
    "        a = torch.randn(in_size, in_size)\n",
    "        # l = torch.nn.Sequential(\n",
    "        #         torch.nn.LayerNorm(in_size),\n",
    "        #         torch.nn.Linear(in_size, out_size, bias=False),\n",
    "        #         activation,\n",
    "        #         torch.nn.LayerNorm(in_size),\n",
    "        #         torch.nn.Linear(in_size, out_size, bias=False),\n",
    "        #         activation,\n",
    "        #         torch.nn.LayerNorm(in_size),\n",
    "        #         torch.nn.Linear(in_size, out_size, bias=False),\n",
    "        #         activation,\n",
    "        #         torch.nn.LayerNorm(in_size),\n",
    "        #         torch.nn.Linear(in_size, out_size, bias=False),\n",
    "        # )\n",
    "\n",
    "        l = torch.nn.Sequential(\n",
    "                torch.nn.LayerNorm(in_size),\n",
    "                torch.nn.Linear(in_size, out_size, bias=False),\n",
    "                activation,\n",
    "                torch.nn.LayerNorm(in_size),\n",
    "                torch.nn.Linear(in_size, out_size, bias=False),\n",
    "        )\n",
    "\n",
    "    # l = torch.nn.Linear(in_size, out_size, bias=False)\n",
    "    # torch.nn.init.orthogonal_(l.weight, gain=gain)\n",
    "        for i, layer in enumerate(l):\n",
    "            if i == len(l) - 1:\n",
    "                gain = 1.0\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                # torch.nn.init.orthogonal_(layer.weight, gain=gain)\n",
    "                fan_out, fan_in = layer.weight.size()\n",
    "                std = gain / math.sqrt(fan_in)\n",
    "                torch.nn.init.normal_(layer.weight, mean=0, std=std)\n",
    "\n",
    "        for _ in range(100):\n",
    "            x = l(a)\n",
    "\n",
    "        # print (f\"Test {test} - input std: {a.std().item():.6f}, out std: {x.std().item():.6f}, difference: {a.std().item() - x.std().item()}\")\n",
    "        if a.std().item() - x.std().item() > 0:\n",
    "            incr_counter +=1\n",
    "        else:\n",
    "            decr_counter +=1\n",
    "    print(f'incr_counter {incr_counter}, decr_counter {decr_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_gain('swiglu', gain=1.735) # decr\n",
    "# test_gain('swiglu', gain=1.55) # decr\n",
    "# test_gain('swiglu', gain=1.33) # decr\n",
    "# test_gain('swiglu', gain=1.3) # decr\n",
    "# test_gain('swiglu', gain=1.25) # incr\n",
    "# test_gain('swiglu', gain=1.27) # incr_counter 174, decr_counter 326\n",
    "# test_gain('swiglu', gain=1.26) # incr\n",
    "# test_gain('swiglu', gain=1.265) # incr_counter 448, decr_counter 52\n",
    "# test_gain('swiglu', gain=1.267) # incr_counter 341, decr_counter 159\n",
    "# test_gain('swiglu', gain=1.268) # incr_counter 293, decr_counter 207\n",
    "# test_gain('swiglu', gain=1.2685) # incr_counter 276, decr_counter 224\n",
    "# test_gain('swiglu', gain=1.2687) # incr_counter 545, decr_counter 455\n",
    "# test_gain('swiglu', gain=1.2688) # incr_counter 486, decr_counter 514\n",
    "# test_gain('swiglu', gain=1.2687) # incr_counter 2568, decr_counter 2432\n",
    "# test_gain('swiglu', gain=1.26875) # incr_counter 2533, decr_counter 2467\n",
    "# test_gain('swiglu', gain=1.26876) # incr_counter 2501, decr_counter 2499\n",
    "# test_gain('swiglu', gain=1.26877) # incr_counter 2501, decr_counter 2499\n",
    "# test_gain('swiglu', gain=1.268765) # incr_counter 5117, decr_counter 4883\n",
    "# test_gain('swiglu', gain=1.2687657) # incr_counter 5053, decr_counter 4947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test gain Progress: 100%|██████████| 5000/5000 [16:06<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incr_counter 2523, decr_counter 2477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test_gain('swiglu', gain=1.26876575) incr_counter 2621, decr_counter 2379\n",
    "test_gain('swiglu', gain=1.2687658)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
